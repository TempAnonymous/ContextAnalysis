{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\81512\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\81512\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\81512\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\81512\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\81512\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\81512\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from UCTB.dataset import NodeTrafficLoader\n",
    "from UCTB.model import XGBoost\n",
    "from UCTB.evaluation import metric\n",
    "from UCTB.preprocess import SplitData\n",
    "from UCTB.preprocess.time_utils import is_work_day_china, is_work_day_america\n",
    "import nni\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use params and args to show its difference\n",
    "args = {\n",
    "    \"dataset\":'Metro',\n",
    "    \"city\":\"Shanghai\",\n",
    "    \"MergeIndex\":1,\n",
    "    \"data_range\":\"all\",\n",
    "    \"train_data_length\":\"all\",\n",
    "    \"MergeWay\":\"sum\",\n",
    "    \"test_ratio\":0.1,\n",
    "    \"closeness_len\":12,\n",
    "    \"period_len\":6,\n",
    "    \"trend_len\":4,\n",
    "    \"external_use\":\"weather-holiday-tp\", # \"weather-holiday-tp\"\n",
    "    \"normalize\":False,\n",
    "    \"max_depth\":8,\n",
    "    \"num_boost_round\":51,\n",
    "    \"poi_distance\":1000\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic shape is: (1368, 288)\n",
      "Weather shape is: (1368, 30)\n",
      "upSample weather feature\n",
      "**** Using Weather feature ****\n",
      "weather feature: (1368, 30)\n",
      "**** Only use Metro service time and Fitness should be 60mins *****\n",
      "**** Using holiday feature ****\n",
      "holiday feature: (1368, 2)\n",
      "**** Using temporal position feature ****\n",
      "hour of day feature: (1368, 24)\n",
      "day of week feature: (1368, 7)\n"
     ]
    }
   ],
   "source": [
    "data_loader = NodeTrafficLoader(dataset=args['dataset'], city=args['city'],\n",
    "                                data_range=args['data_range'], train_data_length=args['train_data_length'],\n",
    "                                test_ratio=args['test_ratio'],\n",
    "                                closeness_len=args['closeness_len'],\n",
    "                                period_len=args['period_len'],\n",
    "                                trend_len=args['trend_len'],\n",
    "                                normalize=False,\n",
    "                                workday_parser=is_work_day_america if args['dataset'] == 'Bike' else is_work_day_china,\n",
    "                                external_use=args['external_use'],\n",
    "                                poi_distance=args['poi_distance'],\n",
    "                                MergeIndex=args['MergeIndex'],\n",
    "                                MergeWay=\"max\" if args[\"dataset\"] == \"ChargeStation\" else \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.poi_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_closeness, val_closeness = SplitData.split_data(\n",
    "    data_loader.train_closeness, [0.9, 0.1])\n",
    "train_period, val_period = SplitData.split_data(\n",
    "    data_loader.train_period, [0.9, 0.1])\n",
    "train_trend, val_trend = SplitData.split_data(\n",
    "    data_loader.train_trend, [0.9, 0.1])\n",
    "if data_loader.external_dim > 0:\n",
    "    train_ef, val_ef = SplitData.split_data(data_loader.train_ef, [0.9, 0.1])\n",
    "if data_loader.poi_dim is not None and data_loader.poi_dim > 0:\n",
    "    train_poi,val_poi = SplitData.split_data(data_loader.poi_feature_train, [0.9, 0.1])\n",
    "    \n",
    "train_y, val_y = SplitData.split_data(data_loader.train_y, [0.9, 0.1])\n",
    "\n",
    "prediction_test = []\n",
    "prediction_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training model...: 100%|█████████████████████████████████████████████████████████████| 288/288 [00:53<00:00,  5.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(data_loader.station_number),desc=\"training model...\"):\n",
    "#for i in range(data_loader.station_number):\n",
    "    #print('Station', i)\n",
    "\n",
    "    model = XGBoost(n_estimators=int(args['num_boost_round']), max_depth=int(args['max_depth']),verbosity=0)\n",
    "\n",
    "    X_Train = []\n",
    "    X_Val = []\n",
    "    X_Test = []\n",
    "    if int(args['closeness_len']) > 0:\n",
    "        X_Train.append(train_closeness[:, i, :, 0])\n",
    "        X_Val.append(val_closeness[:, i, :, 0])\n",
    "        X_Test.append(data_loader.test_closeness[:, i, :, 0])\n",
    "    if int(args['period_len']) > 0:\n",
    "        X_Train.append(train_period[:, i, :, 0])\n",
    "        X_Val.append(val_period[:, i, :, 0])\n",
    "        X_Test.append(data_loader.test_period[:, i, :, 0])\n",
    "    if int(args['trend_len']) > 0:\n",
    "        X_Train.append(train_trend[:, i, :, 0])\n",
    "        X_Val.append(val_trend[:, i, :, 0])\n",
    "        X_Test.append(data_loader.test_trend[:, i, :, 0])\n",
    "    \n",
    "    # append external features\n",
    "    if data_loader.external_dim > 0:\n",
    "        X_Train.append(train_ef)\n",
    "        X_Val.append(val_ef)\n",
    "        X_Test.append(data_loader.test_ef)\n",
    "    \n",
    "    # append poi features\n",
    "    if data_loader.poi_dim is not None and data_loader.poi_dim > 0:\n",
    "        X_Train.append(train_poi[:,i,:])\n",
    "        X_Val.append(val_poi[:,i,:])\n",
    "        X_Test.append(data_loader.poi_feature_test[:,i,:])\n",
    "    \n",
    "    X_Train = np.concatenate(X_Train, axis=-1)\n",
    "    X_Val = np.concatenate(X_Val, axis=-1)\n",
    "    X_Test = np.concatenate(X_Test, axis=-1)\n",
    "\n",
    "    model.fit(X_Train, train_y[:, i, 0])\n",
    "\n",
    "    p_val = model.predict(X_Val)\n",
    "    p_test = model.predict(X_Test)\n",
    "    \n",
    "    prediction_val.append(p_val.reshape([-1, 1, 1]))\n",
    "    prediction_test.append(p_test.reshape([-1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 1, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test.reshape([-1, 1, 1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 288, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(prediction_val, axis=-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (21024,1) (73,288,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-62bcc430fdd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprediction_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Val RMSE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test RMSE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81512\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\UCTB\\evaluation\\metric.py\u001b[0m in \u001b[0;36mrmse\u001b[1;34m(prediction, target, threshold)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         return np.sqrt(np.dot(np.square(prediction - target).reshape([1, -1]),\n\u001b[0m\u001b[0;32m     16\u001b[0m                               target.reshape([-1, 1]) > threshold) / np.sum(target > threshold))[0][0]\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (21024,1) (73,288,1) "
     ]
    }
   ],
   "source": [
    "prediction_test = np.concatenate(prediction_test, axis=-2)\n",
    "prediction_val = np.concatenate(prediction_val, axis=-2)\n",
    "\n",
    "print('Val RMSE', metric.rmse(prediction_val, val_y, threshold=0))\n",
    "print('Test RMSE', metric.rmse(prediction_test, data_loader.test_y, threshold=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(654, 85)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 63)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
